{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "new_feature_creation.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1e9iaxOVVvDh3ljwbQEUp82VrcbocbrSo",
          "timestamp": 1532371062837
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "3KZ6bERrUArI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Set up Environment\n",
        "Update Python and install prerequisite software. Most of this code can be skipped if you are running the Notebook locally, simply make sure you have all the right libraries. I use the following code cell to mount a folder from Google Drive."
      ]
    },
    {
      "metadata": {
        "id": "ZYGcz25GdyBc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools > /dev/null\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse > /dev/null\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UcLv-ti_dyBj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "!pip install -q keras\n",
        "!pip install -q intervaltree\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fIMD2SRoT3Aw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Change to the Google Drive learning directory, or your directory with the libraries and data files"
      ]
    },
    {
      "metadata": {
        "id": "rIDS8RvDdyBq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/learning\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U8pJq9xBT5qX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import Pandas and Numpy\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "0pCiVSoIdyAt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "import numpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P11cJxVNKirT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Set up filenames "
      ]
    },
    {
      "metadata": {
        "id": "K2mLbS4XUHok",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define input and ouput filenames for the files"
      ]
    },
    {
      "metadata": {
        "id": "iXstC0z8dyA1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "input_filename = \"merged.csv\"\n",
        "output_filename = \"output_features_07_26_everything.csv\"\n",
        "output_file = open(output_filename, \"w\", newline = '')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IkSvELhR23fC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load CSV File"
      ]
    },
    {
      "metadata": {
        "id": "9XzLr0nlLGCb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "df = pandas.read_csv(input_filename, dtype=str, keep_default_na=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OhTrPyBa2-q0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Define Helper Function for splitting Entrez IDs"
      ]
    },
    {
      "metadata": {
        "id": "XymMf6vNRdTj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def split_entrez_ids(ids):\n",
        "    entrez_ids = []\n",
        "    if ids.strip() != '':\n",
        "        for entrez_id in ids.strip().split(';'):\n",
        "            entrez_ids.append(int(entrez_id))\n",
        "    return entrez_ids\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K1xCPeZS8TxY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Usage\n",
        "Simply click the run button for every feature you would like added to the CSV. Once you are done adding the features, go to the last line, called Save CSV, and click the run button for that."
      ]
    },
    {
      "metadata": {
        "id": "0ZPkTnLR261H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Keep track of features added"
      ]
    },
    {
      "metadata": {
        "id": "fBkHYGrlcYxO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "list_of_features_added = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_YIU7BFYKeud",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MPO Feature"
      ]
    },
    {
      "metadata": {
        "id": "SWNqnmb-dyBE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# import the mpo library from the ./libraries folder\n",
        "from libraries import mpo\n",
        "\n",
        "#the mpo database is in the ./libraries folder\n",
        "mpo_class = mpo.Gene_to_MPO_Features(\n",
        "    \"./libraries/MPO_topPh_GP20180216.tsv\")\n",
        "\n",
        "# keep track of feature name for column naming\n",
        "feature_name = 'mpo'\n",
        "\n",
        "# warn if feature is already added!\n",
        "if feature_name in list_of_features_added:\n",
        "    print(__name__ + \": Warning: feature '\" +\n",
        "          feature_name + \"' already added to dataframe\")\n",
        "list_of_features_added.append(feature_name)\n",
        "\n",
        "# create dictionary of columns -> list of values for each row\n",
        "final_mpo_dict = {}\n",
        "\n",
        "# These lists represent one column each\n",
        "\n",
        "# multi_entrez_to_num_phenotypes is the total sum of the phenotypes matched\n",
        "list_multi_entrez_to_num_phenotypes = []\n",
        "\n",
        "# multi_entrez_to_num_phenotypes_using_thresh is a more conservative sum\n",
        "# where a gene that matches the same phenotype multitple times is counted only\n",
        "# once.\n",
        "list_multi_entrez_to_num_phenotypes_using_thresh = []\n",
        "\n",
        "# create a key for each column in the dictionary\n",
        "for column in mpo_class.get_all_phenotypes():\n",
        "    final_mpo_dict[feature_name + '_' + column] = []\n",
        "\n",
        "# iterate through every row\n",
        "for ids in df['genes_in_proximity']:\n",
        "    list_multi_entrez_to_num_phenotypes.append(\n",
        "        mpo_class.multi_entrez_to_num_phenotypes(split_entrez_ids(ids)))\n",
        "    list_multi_entrez_to_num_phenotypes_using_thresh.append(\n",
        "        mpo_class.multi_entrez_to_num_phenotypes_using_thresh(\n",
        "            split_entrez_ids(ids)))\n",
        "    for key, value in mpo_class.multi_entrez_to_phenotypes_using_thresh(\n",
        "        split_entrez_ids(ids)).items():\n",
        "        final_mpo_dict[feature_name + '_' + key].append(value)\n",
        "\n",
        "# add all columns from dictionary\n",
        "df = pandas.concat([df, pandas.DataFrame.from_dict(final_mpo_dict)], axis=1)\n",
        "\n",
        "# add new column\n",
        "df[feature_name + \"_multi_entrez_to_num_phenotypes\"] = pandas.DataFrame(\n",
        "    list_multi_entrez_to_num_phenotypes)\n",
        "\n",
        "# add new column\n",
        "df[feature_name +\n",
        "   \"_multi_entrez_to_num_phenotypes_using_thresh\"] = pandas.DataFrame(\n",
        "    list_multi_entrez_to_num_phenotypes_using_thresh)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XqZXXJBLdXOi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# OMIM Feature"
      ]
    },
    {
      "metadata": {
        "id": "_bUrykcibBAo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from libraries import omim\n",
        "omim_class = omim.Gene_to_OMIM_Features(\n",
        "    \"./libraries/OMIMdiseasePhenotypeOnly_gene_info_GP20180213.tsv\")\n",
        "feature_name = 'omim'\n",
        "if feature_name in list_of_features_added:\n",
        "    print(__name__ + \": Warning: feature '\" +\n",
        "          feature_name + \"' already added to dataframe\")\n",
        "\n",
        "list_of_features_added.append(feature_name)\n",
        "\n",
        "# only one column, how many genes are listed in OMIM?\n",
        "list_omim_num_diseases = []\n",
        "for ids in df['genes_in_proximity']:\n",
        "    list_omim_num_diseases.append(\n",
        "        omim_class.multi_entrez_to_num_diseases(split_entrez_ids(ids)))\n",
        "df[feature_name + \"_num_diseases\"] = pandas.DataFrame(list_omim_num_diseases)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1NeQ4snmegJ5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# pLI Feature"
      ]
    },
    {
      "metadata": {
        "id": "yUJl8GP4dtQf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# we need two libraries, one to convert from the entrez ID to the Gene Symbol\n",
        "# and the other to actually give us the pLI of the gene(s)\n",
        "from libraries import entrez_symbol\n",
        "entrez_symbol_class = entrez_symbol.Entrez_Symbol_Lookup(\n",
        "    \"./libraries/map.gsymbol.to.enzid.tsv\")\n",
        "from libraries import gene_pli\n",
        "pli_class = gene_pli.Gene_to_pLI_Features(\n",
        "    \"./libraries/pLI_EXac_broad_institure_2016_03.txt\")\n",
        "feature_name = 'pli'\n",
        "if feature_name in list_of_features_added:\n",
        "    print(__name__ + \": Warning: feature '\"+\n",
        "          feature_name + \"' already added to dataframe\")\n",
        "list_of_features_added.append(feature_name)\n",
        "\n",
        "# the pLI values are binned to be quite granular\n",
        "columns = [\"pli_0.0_to_0.1\", \"pli_0.1_to_0.2\", \"pli_0.2_to_0.3\",\n",
        "           \"pli_0.3_to_0.4\", \"pli_0.4_to_0.5\", \"pli_0.5_to_0.6\",\n",
        "           \"pli_0.6_to_0.7\", \"pli_0.7_to_0.8\", \"pli_0.8_to_0.9\",\n",
        "           \"pli_0.9_to_1.0\"]\n",
        "\n",
        "# once agains we keep a dictionary where each key/column -> list of values\n",
        "final_pli_dict = {}\n",
        "for column in columns:\n",
        "    final_pli_dict[feature_name + '_' + column] = []\n",
        "    \n",
        "# iterate through every row\n",
        "for ids in df['genes_in_proximity']:\n",
        "    # create another temporary dictionary just for the current row,\n",
        "    # so that every key/column -> a single value\n",
        "    row_pli_dict = {}\n",
        "    # initialize all values to 0\n",
        "    for column in columns:\n",
        "        row_pli_dict[column] = 0\n",
        "    for entrez_id in split_entrez_ids(ids):\n",
        "        # there is more than one symbol returned for a given Entrez ID ...\n",
        "        list_symbols = entrez_symbol_class.entrez_id_to_symbols(entrez_id)\n",
        "        max_pli = -2\n",
        "        # find the max pLI of all the \"same\" gene symbols\n",
        "        for symbol in list_symbols:\n",
        "            max_pli = max(max_pli, pli_class.gene_symbol_to_pLI(symbol))\n",
        "        # the library returns '-1' if the gene is not found, so if none of the\n",
        "        # genes are found or no entrez ID translation existed, then max_pli < 0\n",
        "        if max_pli < 0:\n",
        "            continue\n",
        "        elif max_pli <= 0.1:\n",
        "            row_pli_dict[\"pli_0.0_to_0.1\"] += 1\n",
        "        elif max_pli <= 0.2:\n",
        "            row_pli_dict[\"pli_0.1_to_0.2\"] += 1\n",
        "        elif max_pli <= 0.3:\n",
        "            row_pli_dict[\"pli_0.3_to_0.4\"] += 1\n",
        "        elif max_pli <= 0.4:\n",
        "            row_pli_dict[\"pli_0.3_to_0.4\"] += 1\n",
        "        elif max_pli <= 0.5:\n",
        "            row_pli_dict[\"pli_0.4_to_0.5\"] += 1\n",
        "        elif max_pli <= 0.6:\n",
        "            row_pli_dict[\"pli_0.5_to_0.6\"] += 1\n",
        "        elif max_pli <= 0.7:\n",
        "            row_pli_dict[\"pli_0.6_to_0.7\"] += 1\n",
        "        elif max_pli <= 0.8:\n",
        "            row_pli_dict[\"pli_0.7_to_0.8\"] += 1\n",
        "        elif max_pli <= 0.9:\n",
        "            row_pli_dict[\"pli_0.8_to_0.9\"] += 1\n",
        "        elif max_pli <= 1.0:\n",
        "            row_pli_dict[\"pli_0.9_to_1.0\"] += 1\n",
        "    # finally add the current row dictionary to the final dictionary\n",
        "    for key, value in row_pli_dict.items():\n",
        "        final_pli_dict[feature_name + '_' + key].append(value)\n",
        "df = pandas.concat([df, pandas.DataFrame.from_dict(final_pli_dict)], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qWLltvkobfW0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Repetitive Elements\n",
        "Warning: creating this feature may take around an hour.\n",
        "Even loading the library takes a few minutes"
      ]
    },
    {
      "metadata": {
        "id": "ckHtYOQ8Mp91",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from libraries import repeat_elem\n",
        "repeat_class = repeat_elem.Gene_Interval_to_Repetitive_Elements(\n",
        "    \"./libraries/RLCRs_DNN-CNV.txt\")\n",
        "feature_name = 'repeat'\n",
        "if feature_name in list_of_features_added:\n",
        "    print(__name__ + \": Warning: feature '\" +\n",
        "          feature_name + \"' already added to dataframe\")\n",
        "list_of_features_added.append(feature_name)\n",
        "\n",
        "final_repeat_dict = {}\n",
        "# make a column for every repetitive element, e.g. \"LINE\", \"SINE\"\n",
        "for key in repeat_class.set_of_element_types:\n",
        "    final_repeat_dict[feature_name + '_' + key] = []\n",
        "for index, row in df.iterrows():\n",
        "    # this process takes so long, we need a progress update\n",
        "    if index % 100 == 0:\n",
        "        print(\" cnv:\" + str(index), end = '')\n",
        "        \n",
        "    # add to the dictionary for every repetitive element\n",
        "    for key, value in repeat_class.get_all_intersecting_elements(\n",
        "                    row['chr'], int(row['start']), int(row['end'])).items():\n",
        "        final_repeat_dict[feature_name + '_' + key].append(value)\n",
        "df = pandas.concat([df, pandas.DataFrame.from_dict(final_repeat_dict)], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c97EaIw_w-vk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Pathways\n"
      ]
    },
    {
      "metadata": {
        "id": "b7wHL8kgw-T8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from libraries import pathways\n",
        "pathways_class = pathways.Gene_to_Pathways(\n",
        "    \"./libraries/allSizes_GOincludingIEA_pathways_20180213.GMT\")\n",
        "feature_name = 'pathways'\n",
        "if feature_name in list_of_features_added:\n",
        "    print(__name__ + \": Warning: feature '\" +\n",
        "          feature_name + \"' already added to dataframe\")\n",
        "list_of_features_added.append(feature_name)\n",
        "\n",
        "# Get all the Pathways Databases once\n",
        "databases = pathways_class.get_all_databases()\n",
        "# NCI is no longer supported and GO has too many genesets\n",
        "databases.remove(\"NCI\")\n",
        "databases.remove(\"GO\")\n",
        "\n",
        "hugedf = pandas.DataFrame(numpy.zeros((len(df), 1)), columns = ['drop'])\n",
        "for database in databases:\n",
        "    for line_num in pathways_class._dict_databases_to_lines[database]:\n",
        "        hugedf[database + '_' + str(line_num)] = 0\n",
        "    for index, row in df.iterrows():\n",
        "        for key, descrip, value in pathways_class.multi_entrez_to_gene_sets(\n",
        "                              split_entrez_ids(row['genes_in_proximity']),\n",
        "                              database, filter_min = 30, filter_max = 1000):\n",
        "            hugedf.at[index, database + '_' + str(key)] = str(value)\n",
        "hugedf.drop(['drop'], axis=1)\n",
        "df = pandas.concat([df, hugedf], axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R_vESGxo76P3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Save CSV"
      ]
    },
    {
      "metadata": {
        "id": "8IW4EQewx03i",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "df.to_csv(output_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}